{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Poem Generator Model 2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIlRg97QfJVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import numpy\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,LSTM\n",
        "from keras.utils import np_utils\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkLsZb_6fJVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"sonnets.txt\"\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSrSidMpfJVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHFHeMm7gJv9",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DobJxJLfJVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FopwzhmfJVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "    seq_in = raw_text[i:i + seq_length]\n",
        "    seq_out = raw_text[i + seq_length]\n",
        "    dataX.append([char_to_int[char] for char in seq_in])\n",
        "    dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTUZizY1fJVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "X = X / float(n_vocab)\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huUQxKkWfJV1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "161cf9f6-13dd-4b4b-86e5-d59977ae54d7"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(700,input_shape=(X.shape[1], X.shape[2]),return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(700,return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(700))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0807 14:37:20.388845 140357708863360 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0807 14:37:20.426461 140357708863360 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0807 14:37:20.431976 140357708863360 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0807 14:37:21.542792 140357708863360 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0807 14:37:21.553671 140357708863360 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 100, 700)          1965600   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 700)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100, 700)          3922800   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100, 700)          0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 700)               3922800   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 700)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 38)                26638     \n",
            "=================================================================\n",
            "Total params: 9,837,838\n",
            "Trainable params: 9,837,838\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3gFTrUEfJV6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "8a1e5324-cf62-45cf-9cf4-b0f006e08a1a"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0807 14:37:23.851083 140357708863360 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0807 14:37:23.876521 140357708863360 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRLyV2SXfJV8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "5c08be5a-a752-4b4e-cddd-0f819bf9a2d8"
      },
      "source": [
        "model.fit(X,y,epochs=20,batch_size=128)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "93982/93982 [==============================] - 469s 5ms/step - loss: 2.8063\n",
            "Epoch 2/20\n",
            "93982/93982 [==============================] - 469s 5ms/step - loss: 2.4504\n",
            "Epoch 3/20\n",
            "93982/93982 [==============================] - 468s 5ms/step - loss: 2.2234\n",
            "Epoch 4/20\n",
            "93982/93982 [==============================] - 468s 5ms/step - loss: 2.0667\n",
            "Epoch 5/20\n",
            "93982/93982 [==============================] - 468s 5ms/step - loss: 1.9407\n",
            "Epoch 6/20\n",
            "93982/93982 [==============================] - 468s 5ms/step - loss: 1.8411\n",
            "Epoch 7/20\n",
            "93982/93982 [==============================] - 468s 5ms/step - loss: 1.7437\n",
            "Epoch 8/20\n",
            "93982/93982 [==============================] - 468s 5ms/step - loss: 1.6601\n",
            "Epoch 9/20\n",
            "93982/93982 [==============================] - 467s 5ms/step - loss: 1.5732\n",
            "Epoch 10/20\n",
            "93982/93982 [==============================] - 467s 5ms/step - loss: 1.4774\n",
            "Epoch 11/20\n",
            "93982/93982 [==============================] - 467s 5ms/step - loss: 1.3863\n",
            "Epoch 12/20\n",
            "93982/93982 [==============================] - 467s 5ms/step - loss: 1.2789\n",
            "Epoch 13/20\n",
            "93982/93982 [==============================] - 467s 5ms/step - loss: 1.1811\n",
            "Epoch 14/20\n",
            "93982/93982 [==============================] - 470s 5ms/step - loss: 1.0779\n",
            "Epoch 15/20\n",
            "93982/93982 [==============================] - 469s 5ms/step - loss: 0.9882\n",
            "Epoch 16/20\n",
            "93982/93982 [==============================] - 468s 5ms/step - loss: 0.9065\n",
            "Epoch 17/20\n",
            "93982/93982 [==============================] - 469s 5ms/step - loss: 0.8291\n",
            "Epoch 18/20\n",
            "93982/93982 [==============================] - 467s 5ms/step - loss: 0.7506\n",
            "Epoch 19/20\n",
            "93982/93982 [==============================] - 467s 5ms/step - loss: 0.6826\n",
            "Epoch 20/20\n",
            "93982/93982 [==============================] - 467s 5ms/step - loss: 0.6494\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa78cb92630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znvi-qTAfJV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('text_generator_700_0.2_700_0.2_100.h5')\n",
        "model.load_weights('text_generator_700_0.2_700_0.2_100.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5lQUKTZfJWB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "cd9c8304-3e5f-4731-fca8-723052052dea"
      },
      "source": [
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "full_string = [int_to_char[value] for value in pattern]\n",
        "for i in range(1000):\n",
        "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = x / float(n_vocab)\n",
        "    \n",
        "    prediction = model.predict(x, verbose=0)\n",
        "    index = numpy.argmax(prediction)\n",
        "    result = int_to_char[index]\n",
        "    seq_in = [int_to_char[value] for value in pattern]\n",
        "    full_string.append(int_to_char[index])\n",
        "    sys.stdout.write(result)\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "thy sweet self to breed another thee,\n",
            "or else of thee thy self thy sweet self prove:\n",
            "for all the brain of well-refined pen.\n",
            "hearing you have thy love should eespair,\n",
            "and tueh a counterpart shall with thowghts on thee,\n",
            "and thou art the grave what she is desire.\n",
            "whilst i, my love shall in my verse\n",
            "and this my love aray,\n",
            "if thou wilt leave thy self to break a wasya\n",
            "and therefore would ceauty being mute,\n",
            "when thou art thy sweet self to boess doth day,\n",
            "and make me sravel forth with my jealous thought\n",
            "where you may be still my part,\n",
            "and to his sweet self prove cost hide,\n",
            "what every humour hath my adder's sense\n",
            "to crief mind own sweet searon doth shall read;\n",
            "self so be remembered with the time where buried live,\n",
            "which but the self-love world courh sp thee my friend'and me!\n",
            "is'it thou thy self thy sweet self dost deceive:\n",
            "then look i death my self amother shade\n",
            "of his spirit?\n",
            "when all the brain whereof should ce than all thy breast;\n",
            "i, my slok with sighs and thy self defence.\n",
            "\n",
            "lo  thou art to \n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcwx-Kz3fJWG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "1dc607ed-7183-45d5-e7a4-365bf81b21f3"
      },
      "source": [
        "txt=\" \"\n",
        "for char in full_string:\n",
        "    txt=txt+char\n",
        "    txt.replace('\\n',' \\n ')\n",
        "print(txt)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  will more.\n",
            "let no unkind, no fair beseechers kill;\n",
            "think all but one, and me in that one will.\n",
            "\n",
            "if thy sweet self to breed another thee,\n",
            "or else of thee thy self thy sweet self prove:\n",
            "for all the brain of well-refined pen.\n",
            "hearing you have thy love should eespair,\n",
            "and tueh a counterpart shall with thowghts on thee,\n",
            "and thou art the grave what she is desire.\n",
            "whilst i, my love shall in my verse\n",
            "and this my love aray,\n",
            "if thou wilt leave thy self to break a wasya\n",
            "and therefore would ceauty being mute,\n",
            "when thou art thy sweet self to boess doth day,\n",
            "and make me sravel forth with my jealous thought\n",
            "where you may be still my part,\n",
            "and to his sweet self prove cost hide,\n",
            "what every humour hath my adder's sense\n",
            "to crief mind own sweet searon doth shall read;\n",
            "self so be remembered with the time where buried live,\n",
            "which but the self-love world courh sp thee my friend'and me!\n",
            "is'it thou thy self thy sweet self dost deceive:\n",
            "then look i death my self amother shade\n",
            "of his spirit?\n",
            "when all the brain whereof should ce than all thy breast;\n",
            "i, my slok with sighs and thy self defence.\n",
            "\n",
            "lo  thou art to \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biqS-sYYfJWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfMTq0jEfJWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}